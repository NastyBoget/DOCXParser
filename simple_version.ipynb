{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Манифест\n",
    "\n",
    "Выделяется структура из текстовых документов.\n",
    "Необходимо для каждого параграфа документа определить его тип и уровень вложенности относительно всего документа. \n",
    "\n",
    "На вход последовательно подается список параграфов документа. Для каждого параграфа необходимо определить его тип: заголовок, список, текст или другое, а также пометить увеличивается ли уровень вложенности документа, не меняется или уменьшается, если уменьшается или увеличивается, то насколько.\n",
    "\n",
    "#### 1. Заголовок\n",
    "\n",
    "Заголовок всего документа обычно располагается в начале документа, подзаголовки, как правило, начинают новую главу, подглаву, секцию и т. д. Может располагаться по центру, выделяться жирным шрифтом, курсивом и т. д.\n",
    "\n",
    "#### 2. Список\n",
    "\n",
    "Пронумерованная (числами, буквами или специальными маркерами) последовательность строк. Начинается с нумерации и как правило, располагается рядом с аналогично пронумерованными строками.\n",
    "\n",
    "#### 3. Текст\n",
    "\n",
    "Все остальные строки, содержащие текст.\n",
    "\n",
    "#### Об уровнях вложенности\n",
    "\n",
    "Изначальный уровень вложенности документа - 0. То есть первый заголовок документа имеет вложенность 0, так же как и любой текст до этого заголовка. Текст, следующий после этого заголовка (относящийся к данному заголовку), имеет уровень вложенности, больший на 1. Элементы списков имеют уровень вложенности, зависящий от того, куда они вкладываются. Если список является частью текстового блока, то он имеет такой же уровень, как и этот текстовый блок. Если список вложен в другой список, то его уровень вложенности увеличивается на 1.\n",
    "\n",
    "При понижении уровня необходимо смотреть, продолжением какого списка или к заголовку какого уровня относится очередной параграф документа.\n",
    "\n",
    "Каждому параграфу нужно сопоставить два числа - номер типа параграфа (либо 0, если другое) и уровень вложенности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Идея для более удобной разметки: отображать docx документ на странице, выделяя строку, которую нужно пометить, цветом. Можно отображать рядом текст размеченных строк и их метки. После разметки целого документа добавить возможность переразметки. [(Может пригодиться)](https://www.cyberforum.ru/html/thread1762308.html)\n",
    "\n",
    "* корректность работы docx-парсера???\n",
    "\n",
    "* составление дерева на основе уровней и типов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_parser import DOCXParser\n",
    "import os\n",
    "import json\n",
    "import docx\n",
    "import re\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document = docx.Document('examples/train_examples/0.docx')\n",
    "# document.paragraphs[0].runs[0].font.color.rgb = docx.shared.RGBColor(0xff, 0x99, 0xcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [{\"name\", \"paragrahps\": [{\"text\", \"type\", \"level\"}]}]\n",
    "# type - header - 1, list - 2, text - 3\n",
    "# numeration begins with 0\n",
    "results = []\n",
    "\n",
    "for i in range(1, 4):\n",
    "    path = f\"examples/test_examples/{i}.docx\"\n",
    "    document = docx.Document(path)\n",
    "    item = {\"name\": path, \"paragraphs\": []}\n",
    "    end = False\n",
    "    while not end:\n",
    "        for paragraph in document.paragraphs:\n",
    "            if not paragraph.text.strip():\n",
    "                continue\n",
    "            p = {\"text\": paragraph.text}\n",
    "            print(paragraph.text)\n",
    "            type_ = input(\"type: \")\n",
    "            level = input(\"level: \")\n",
    "            p[\"type\"] = type_\n",
    "            p[\"level\"] = level\n",
    "            item[\"paragraphs\"].append(p)\n",
    "        answer = input(\"end?\")\n",
    "        if answer == \"y\":\n",
    "            end = True\n",
    "            results.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('examples/train_examples/labeled.json', \"w\") as f:\n",
    "#     json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('examples/test_examples/labeled.json', \"r\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_test_data = []\n",
    "\n",
    "for item in test_data:\n",
    "    new_item = {\"name\": item[\"name\"], \"paragraphs\": []}\n",
    "    for p in item['paragraphs']:\n",
    "        p_info = {}\n",
    "        if p['text'].strip():\n",
    "            p_info['text'] = p['text'].strip()\n",
    "            p_info['type'] = int(p['type'])\n",
    "            p_info['level'] = int(p['level'])\n",
    "            new_item[\"paragraphs\"].append(p_info)\n",
    "    if new_item[\"paragraphs\"]:\n",
    "        clear_test_data.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_data[3]['paragraphs'] = clear_data[3]['paragraphs'][:4]\n",
    "# clear_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_without_labels = []\n",
    "test_labels = []\n",
    "\n",
    "for item in clear_test_data:\n",
    "    new_item = {\"name\": item[\"name\"], \"paragraphs\": []}\n",
    "    for p in item['paragraphs']:\n",
    "        new_item[\"paragraphs\"].append(p[\"text\"])\n",
    "        test_labels.append((p[\"type\"], p[\"level\"]))\n",
    "    test_data_without_labels.append(new_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Признаки\n",
    "\n",
    "* жирность, курсив, подчеркивание, размер, выравнивание, отступ с помощью DOCXParser\n",
    "* число символов в первом слове\n",
    "* число цифр в первом слове\n",
    "* длина строки\n",
    "* начало с тире, цифры, буквы и т. п.\n",
    "* те же признаки для предыдущего и следующего параграфов\n",
    "* наличие стиля heading, type из DOCXParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment2number = {\n",
    "    \"left\": 0,\n",
    "    \"right\": 1,\n",
    "    \"center\": 2,\n",
    "    \"both\": 3\n",
    "}\n",
    "\n",
    "type2number = {\n",
    "    \"paragraph\": 1,\n",
    "    \"list_item\": 2,\n",
    "    \"raw_text\": 3\n",
    "}\n",
    "\n",
    "\n",
    "def find_paragraph(paragraph_list, text):\n",
    "    for p in paragraph_list:\n",
    "        # TODO correct comparison\n",
    "#         print(f\"real text={' '.join(p['text'].split())}\")\n",
    "#         print(f\"text={' '.join(text.split())}\")\n",
    "#         print(\"===========\")\n",
    "        if \" \".join(p[\"text\"].split()).find(\" \".join(text.split())) != -1:\n",
    "            result = p.copy()\n",
    "            paragraph_list.remove(p)\n",
    "            return result\n",
    "    return None\n",
    "#     raise KeyError(f\"paragraph {text} not found in the document {paragraph_list}\")\n",
    "    \n",
    "\n",
    "def extract_annotations(annotations):\n",
    "    result = {\"indent\": [0, 0, 0, 0], \"alignment\": 0, \"size\": 0, \"bold\": 0, \"italic\": 0, \"underlined\": 0}\n",
    "    if not annotations:\n",
    "        return result\n",
    "    for start, end, annotation in annotations:\n",
    "        if annotation.startswith(\"indent\"):\n",
    "            d = json.loads(re.sub(\"'\", '\"', annotation[7:]))\n",
    "            result[\"indent\"] = [d[\"left\"], d[\"start\"], d[\"hanging\"], d[\"firstLine\"]]\n",
    "        elif annotation.startswith(\"alignment\"):\n",
    "            result[\"alignment\"] = alignment2number[annotation[10:]]\n",
    "        elif annotation.startswith(\"size\"):\n",
    "            result[\"size\"] = int(annotation[5:])\n",
    "        else:\n",
    "            for item in [\"bold\", \"italic\", \"underlined\"]:\n",
    "                if annotation.startswith(item):\n",
    "                    result[item] = 1\n",
    "                    break\n",
    "    return result\n",
    "            \n",
    "\n",
    "def extract_doc_features(docs_info):\n",
    "    \"\"\"\n",
    "    docs_info = list of {\"name\", \"paragraphs\": [\"text of 1 line\", \"text of 2 line\"]}\n",
    "    returns list of features for each paragraph\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for doc_info in docs_info:\n",
    "        path = doc_info[\"name\"]\n",
    "        parser = DOCXParser(path)\n",
    "        lines_info = parser.get_lines_with_meta()\n",
    "        for p in doc_info[\"paragraphs\"]:\n",
    "            p_features = []\n",
    "            p_info = find_paragraph(lines_info, p)\n",
    "            if p_info:\n",
    "                p_features.append(type2number[p_info[\"type\"]])\n",
    "            else:\n",
    "                p_features.append(3)\n",
    "                p_info = {\"text\": \"\", \"annotations\": None}\n",
    "            p_annotations = extract_annotations(p_info[\"annotations\"])\n",
    "            p_features += p_annotations[\"indent\"]\n",
    "            p_features += [p_annotations[\"alignment\"], p_annotations[\"size\"], \n",
    "                          p_annotations[\"bold\"], p_annotations[\"italic\"], p_annotations[\"underlined\"]]\n",
    "            p_features.append(len(p_info[\"text\"].split()))\n",
    "            \n",
    "            if p_info[\"text\"].split():\n",
    "                first_word = p_info[\"text\"].split()[0]\n",
    "            else:\n",
    "                first_word = \"\"\n",
    "            p_features.append(len(first_word))\n",
    "            p_features.append(len(re.findall(r\"\\d+\", first_word)))\n",
    "            features.append(p_features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = extract_doc_features(test_data_without_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55, 13), 55)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape, len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [y*10 + x for x, y in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.fit(features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.518019437877594"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y, clf.predict(test_features), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}